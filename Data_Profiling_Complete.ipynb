{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c5f4576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "import os\n",
    "import sys\n",
    "from scipy.stats import entropy\n",
    "from spellchecker import SpellChecker\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.plotting import figure, output_file, save\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.embed import file_html\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.palettes import Spectral6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c765ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mngr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf245c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "file type detectio algo \n",
    "\n",
    "input = data path\n",
    "output = classification [structured, unstructured], extension = [xls, csv, jpeg, etc.]\n",
    "\n",
    "\n",
    "'''\n",
    "def check_input(input_path):\n",
    "    \n",
    "    #Global variable to store data type and format \n",
    "    dict = {}\n",
    "    \n",
    "    # Checking if the input path exists\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Error: {input_path} does not exist\")\n",
    "        return\n",
    "\n",
    "    # Checking if the input path is a file\n",
    "    if os.path.isfile(input_path):\n",
    "        # Check if the input is structured \n",
    "        file_extension = os.path.splitext(input_path)[1]\n",
    "        if file_extension in ['.csv', '.xlsx','xls']:\n",
    "            dict['classification'] = 'structured'\n",
    "            dict['extension'] = file_extension\n",
    "            return dict\n",
    "            \n",
    "        #Checking in the input is unstructured    \n",
    "        elif file_extension in ['.txt']:\n",
    "            dict['classification'] = 'unstructured'\n",
    "            dict['extension'] = file_extension\n",
    "            return dict\n",
    "            \n",
    "        #Checking is the input is semi-structured    \n",
    "        elif file_extension in ['.json']:\n",
    "            dict['classification'] = 'semi-structured'\n",
    "            dict['extension'] = file_extension\n",
    "            return dict\n",
    "        \n",
    "        else:\n",
    "            dict['classification'] = 'unknown'\n",
    "            dict['extension'] = file_extension\n",
    "            return dict\n",
    "            #print(f\"{input_path} does not fit any current criteria\")\n",
    "            \n",
    "    # Check if the input path is a directory\n",
    "    elif os.path.isdir(input_path):\n",
    "        # Check if the directory contains images or videos\n",
    "        contains_images = False\n",
    "        contains_videos = False\n",
    "        for filename in os.listdir(input_path):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "                contains_images = True\n",
    "                \n",
    "            elif filename.endswith(('.mp4', '.avi', '.mov', '.wmv')):\n",
    "                contains_videos = True\n",
    "                \n",
    "        if contains_images and contains_videos:\n",
    "            dict['classification'] = 'unstructured'\n",
    "            dict['extension'] = file_extension\n",
    "            return dict\n",
    "           \n",
    "        elif contains_images:\n",
    "            dict['classification'] = 'unstructured'\n",
    "            dict['extension'] = file_extension\n",
    "            return dict\n",
    "            \n",
    "        elif contains_videos:\n",
    "            dict['classification'] = 'unstructured'\n",
    "            dict['extension'] = file_extension\n",
    "            return dict\n",
    "            \n",
    "        else:\n",
    "            print(f\"{input_path} is an empty directory\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"{input_path} is not a file or directory\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a8658",
   "metadata": {},
   "source": [
    "## Structured Data Metadata Generation Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b039a",
   "metadata": {},
   "source": [
    "#### Nulls M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b97eaa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input:\n",
    "A pandas dataframe df\n",
    "\n",
    "Output:\n",
    "\n",
    "A new pandas dataframe with the same shape as the input df, where every cell that is a null is populated with \n",
    "a 1, and every other cell with a 0.\n",
    "\n",
    "\n",
    "Function description:\n",
    "The nulls_value function takes in a pandas dataframe and returns a new dataframe of the same shape \n",
    "where each cell containing a null value (as defined in the function) is replaced with a 1, and every other cell is \n",
    "replaced with a 0. The function first defines a nested helper function to determine if a given cell value is null. \n",
    "It then applies this helper function element-wise to all cells in the input dataframe using the applymap method. \n",
    "Finally, the function returns the resulting new dataframe.\n",
    "\n",
    "Input:\n",
    "   A     B     C    D\n",
    "0  1   NaN   3.0   aa\n",
    "1  4   5.0   6.0  NaN\n",
    "2  7   8.0   NaN   bb\n",
    "3  9  10.0  11.0   cc\n",
    "\n",
    "Output:\n",
    "   A  B  C  D\n",
    "0  0  1  0  0\n",
    "1  0  0  0  1\n",
    "2  0  0  1  0\n",
    "3  0  0  0  0\n",
    "\n",
    "'''\n",
    "def nulls_value(df):\n",
    "    def is_null(val):\n",
    "        if isinstance(val, str) and val.lower() in ['null', 'nan', 'n/a', 'na' , '']:\n",
    "            return 1\n",
    "        elif isinstance(val, float) and np.isnan(val):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    output_df = df.applymap(is_null)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0713aa01",
   "metadata": {},
   "source": [
    "#### Value Length M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "815e72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input:\n",
    "\n",
    "A pandas dataframe df\n",
    "\n",
    "Output:\n",
    "\n",
    "A new pandas dataframe with the same shape as the input df, where each cell is replaced by the length \n",
    "of the value populating that cell.\n",
    "\n",
    "Function description:\n",
    "The value_length function takes in a pandas dataframe and returns a new dataframe with the same shape where \n",
    "each cell is replaced by the length of the value populating that cell. The function first defines a nested \n",
    "helper function to get the length of the string representation of a given cell value. It then applies this \n",
    "helper function element-wise to all cells in the input dataframe using the applymap method. Finally, the \n",
    "function returns the resulting new dataframe.\n",
    "\n",
    "\n",
    "Input:\n",
    "    col1  col2  col3\n",
    "0   123   abc   True\n",
    "1  3.14  None  None\n",
    "2   def   NaN   456\n",
    "\n",
    "\n",
    "output:\n",
    "    col1  col2  col3\n",
    "0     3     3     4\n",
    "1     4     0     0\n",
    "2     3     3     3\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def value_length(df):\n",
    "    def get_value_length(val):\n",
    "        return len(str(val))\n",
    "\n",
    "    output_df = df.applymap(get_value_length)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d8618f",
   "metadata": {},
   "source": [
    "#### Size M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5013afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Input = dataframe(df) of shape n*m\n",
    "Output = dataframe of shape n*m\n",
    "\n",
    "Operations:\n",
    "Calculates size of each cell in bytes. \n",
    "\n",
    "'''\n",
    "\n",
    "def cell_size(df):\n",
    "    \n",
    "    # Blank dictionary to story cell size info\n",
    "    cell_size_info = {}\n",
    "    \n",
    "    # Iterating through each column and row to get the cell size information\n",
    "    for col in df.columns:\n",
    "        cell_size = []\n",
    "        for val in df[col]:\n",
    "            cell_size.append(sys.getsizeof(val))\n",
    "        cell_size_info[col] = cell_size\n",
    "    \n",
    "    # Create a DataFrame from the cell size information\n",
    "    df_cell_sizes = pd.DataFrame(cell_size_info)\n",
    "\n",
    "    return df_cell_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f4386",
   "metadata": {},
   "source": [
    "#### Data Type M4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b9545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_data_type(df):\n",
    "    '''\n",
    "    This function takes in a pandas dataframe and returns a new dataframe with the same shape\n",
    "    where each cell is replaced by the data type of the value populating that cell.\n",
    "    \n",
    "    Input:\n",
    "        - df: pandas dataframe\n",
    "        \n",
    "    Output:\n",
    "        - A new pandas dataframe with the same shape as the input dataframe, where each cell \n",
    "          is replaced by the data type of the value populating that cell.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Input:\n",
    "         col1  col2  col3\n",
    "    0   123   abc   True\n",
    "    1  3.14  None  None\n",
    "    2   def   NaN   456\n",
    "    \n",
    "    \n",
    "    \n",
    "    Output:\n",
    "        col1     col2       col3\n",
    "    0    int      str       bool\n",
    "    1  float  unknown    unknown\n",
    "    2    str  unknown      int64\n",
    "\n",
    "    '''\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    for col in df.columns:\n",
    "        output_df[col] = df[col].apply(lambda x: 'unknown' if pd.isna(x) else type(x).__name__)\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0126865a",
   "metadata": {},
   "source": [
    "#### Value Count M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08eb98d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_count(df):\n",
    "    '''\n",
    "    This function takes in a pandas dataframe and returns a dictionary for each column,\n",
    "    where the keys of the dictionary are unique values in that column, and the values \n",
    "    are the number of occurrences of each unique value.\n",
    "    \n",
    "    Input:\n",
    "        - df: pandas dataframe\n",
    "        \n",
    "    Output:\n",
    "        - A dictionary of value counts for each column in the input dataframe.\n",
    "        \n",
    "        \n",
    "    input:\n",
    "        col1 col2 col3\n",
    "    0     1    A    X\n",
    "    1     2    B    Y\n",
    "    2     2    A    X\n",
    "    3     1    B    Z\n",
    "    4     3    C    Y\n",
    "    5     1    C    Z\n",
    "    6     2    A    Z\n",
    "    7     2    B    X\n",
    "\n",
    "\n",
    "    output:\n",
    "    {\n",
    "        'col1': {1: 3, 2: 4, 3: 1},\n",
    "        'col2': {'A': 3, 'B': 2, 'C': 2},\n",
    "        'col3': {'X': 3, 'Y': 2, 'Z': 3}\n",
    "    }\n",
    "    '''\n",
    "    output_dict = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        value_counts = df[col].value_counts().to_dict()\n",
    "        output_dict[col] = value_counts\n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d906e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3235cb0a",
   "metadata": {},
   "source": [
    "#### Z Score (Numeric) M6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b37736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(df):\n",
    "    '''\n",
    "    This function takes in a pandas dataframe and calculates the z-scores of each\n",
    "    value in each numeric column, returning a new dataframe with the same shape as\n",
    "    the input dataframe, but with the values of each numeric column replaced by\n",
    "    their z-scores within the column.\n",
    "\n",
    "    Input:\n",
    "        - df: pandas dataframe\n",
    "\n",
    "    Output:\n",
    "        - A new pandas dataframe with the same shape as the input dataframe, but with\n",
    "          the values of each numeric column replaced by their z-scores within the column.\n",
    "\n",
    "    Input:\n",
    "      col1  col2  col3\n",
    "    0     1   100     5\n",
    "    1     2   200    10\n",
    "    2     3   300    15\n",
    "    3     4   400    20\n",
    "    4     5   500    25\n",
    "\n",
    "    Output:\n",
    "          col1      col2\n",
    "    0 -1.414214 -1.414214\n",
    "    1 -0.707107 -0.707107\n",
    "    2  0.000000  0.000000\n",
    "    3  0.707107  0.707107\n",
    "    4  1.414214  1.414214\n",
    "    '''\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Convert 'object' datatype columns containing numeric data to the appropriate numeric datatype\n",
    "    for col in df_copy.columns:\n",
    "        if df_copy[col].dtype == 'object':\n",
    "            df_copy[col] = pd.to_numeric(df_copy[col], errors='ignore')\n",
    "\n",
    "    numeric_cols = df_copy.select_dtypes(include=['float', 'int', 'float64', 'float32', 'float16']).columns\n",
    "    zscore_df = df_copy[numeric_cols].copy()\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        #if df_copy[col].isnull().all():\n",
    "        #    print('in')\n",
    "        #    continue  # skip the column if it has all nulls\n",
    "        zscores = stats.zscore(df_copy[col], nan_policy='omit')\n",
    "        zscore_df[col] = zscores\n",
    "    \n",
    "    \n",
    "    zscore_df = zscore_df.dropna(how='all', axis=1)\n",
    "    return zscore_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23cbc81",
   "metadata": {},
   "source": [
    "#### Z Score (Value Length) M7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f9cda2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_value_length(df):\n",
    "    \n",
    "    '''\n",
    "    Value Lenght Z Score for Non Numeric Data\n",
    "    \n",
    "    This function takes in a pandas dataframe and calculates the z-scores of each\n",
    "    cell value length in each non-numeric column, returning a new dataframe with the\n",
    "    same shape as the input dataframe, but with the cell values of each non-numeric column\n",
    "    replaced by their z-scores based on the length of the cell value.\n",
    "    \n",
    "    Input:\n",
    "        - df: pandas dataframe\n",
    "        \n",
    "    Output:\n",
    "        - A new pandas dataframe with only the non-numeric columns and with the same shape\n",
    "          as the input dataframe, but with the cell values of each non-numeric column\n",
    "          replaced by their z-scores based on the length of the cell value.\n",
    "          \n",
    "          \n",
    "    Input:\n",
    "        col1  col2    col3  col4\n",
    "    0  abcd   1.2   apple     5\n",
    "    1    ab   2.4  banana     6\n",
    "    2  abcde   3.6   peach     7\n",
    "    3   abc   4.8  orange     8\n",
    "\n",
    "\n",
    "    Output:\n",
    "\n",
    "            col1      col3\n",
    "    0  -0.205583 -0.872872\n",
    "    1  -1.468296  0.218218\n",
    "    2   1.555266  1.309307\n",
    "    3  -0.881387 -0.654653\n",
    "    '''\n",
    "    non_numeric_cols = df.select_dtypes(exclude=['float', 'int']).columns\n",
    "    zscore_df = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for col in non_numeric_cols:\n",
    "        if not df[col].isnull().all():\n",
    "            value_lengths = df[col].astype(str).apply(len)\n",
    "            zscores = stats.zscore(value_lengths)\n",
    "            zscore_df[col] = zscores\n",
    "    \n",
    "    return zscore_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db33de",
   "metadata": {},
   "source": [
    "#### Decimals M8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dcfb2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_decimal_values(df):\n",
    "    '''\n",
    "    This function takes in a pandas dataframe and returns a new dataframe with only the numeric columns,\n",
    "    where the cell values are replaced with the number of decimal places of the corresponding values.\n",
    "    \n",
    "    Input:\n",
    "        - df: pandas dataframe\n",
    "        \n",
    "    Output:\n",
    "        - A new pandas dataframe with only the numeric columns of the input dataframe,\n",
    "          where the cell values are replaced with the number of decimal places of the corresponding values.\n",
    "          \n",
    "    Input:          \n",
    "        col1    col2     col3   col4\n",
    "    0     1  1.2000  1.00000      A\n",
    "    1     2  2.3400  2.00000     BB\n",
    "    2     3  3.4560  3.00000    CCC\n",
    "    3     4  4.5678  4.00000   DDDD\n",
    "    4     5  5.6789  5.00000  EEEEE\n",
    "\n",
    "\n",
    "    Output:\n",
    "        col2  col3\n",
    "    0     1     0\n",
    "    1     2     0\n",
    "    2     3     4\n",
    "    3     4     5\n",
    "    4     5     5\n",
    "    '''\n",
    "    # Filter the numeric columns in the input dataframe\n",
    "    num_cols = df.select_dtypes(include=['float', 'int']).columns\n",
    "    \n",
    "    # Create a new dataframe to store the decimal place counts for each cell value\n",
    "    decimal_count_df = pd.DataFrame(index=df.index, columns=num_cols)\n",
    "    # Check if there are any numeric columns in the input dataframe\n",
    "    #print(len(decimal_count_df))\n",
    "    if len(num_cols) == 0:\n",
    "        # If there are no numeric columns, return an empty dataframe with the same index as the input dataframe\n",
    "        return pd.DataFrame(index=df.index)\n",
    "    # Loop through each numeric column in the input dataframe\n",
    "    # Loop through each numeric column in the input dataframe\n",
    "    for col in num_cols:\n",
    "        try:\n",
    "            # Convert the column to a string data type and split each cell value at the decimal point\n",
    "            decimal_parts = df[col].astype(str).str.split('.', expand=True)\n",
    "            # Calculate the number of decimal places for each cell value and assign it to the corresponding cell \n",
    "            # in the output dataframe\n",
    "            decimal_count_df[col] = decimal_parts[1].str.len().fillna(0).astype(int)\n",
    "        except:\n",
    "            # If an exception is raised during the loop, set the corresponding column in the output dataframe to null\n",
    "            decimal_count_df[col] = np.nan\n",
    "    \n",
    "    \n",
    "    return decimal_count_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae94d6d2",
   "metadata": {},
   "source": [
    "### Column Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad46f9e",
   "metadata": {},
   "source": [
    "#### Inconsistency M9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c21d385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_elements(lst):\n",
    "    counts = {}\n",
    "    for elem in lst:\n",
    "        if elem in counts:\n",
    "            counts[elem] += 1\n",
    "        else:\n",
    "            counts[elem] = 1\n",
    "    return [counts[elem] for elem in lst]\n",
    "\n",
    "\n",
    "def column_inconsistency(col):\n",
    "    # check if column is numeric\n",
    "    if not pd.api.types.is_numeric_dtype(col):\n",
    "        col = count_elements(col)\n",
    "\n",
    "    # calculate the standard deviation of the column\n",
    "    std_dev = np.std(col)\n",
    "\n",
    "    # calculate the inconsistency\n",
    "    inconsistency = std_dev / np.mean(col)\n",
    "\n",
    "    return inconsistency\n",
    "\n",
    "\n",
    "def get_column_inconsistency(df):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe as input and returns a dataframe with two columns - column name and inconsistency.\n",
    "    Higher inconsistency values indicate higher inconsistencies in the column data.\n",
    "\n",
    "    Inputs:\n",
    "    A pandas dataframe with any number of columns and rows.\n",
    "\n",
    "    Outputs:\n",
    "    A pandas dataframe with two columns - column name and inconsistency.\n",
    "    \n",
    "    \n",
    "    Input:\n",
    "        name  age gender\n",
    "    0  Alice   25      F\n",
    "    1    Bob   30      M\n",
    "    2   Charlie  35      M\n",
    "    \n",
    "          Column  inconsistency\n",
    "    0           name       0.000000\n",
    "    1            age       0.057982\n",
    "    2         gender       0.408248\n",
    "    \n",
    "    \"\"\"\n",
    "    inconsistency_dict = {}\n",
    "    for col in df.columns:\n",
    "        inconsistency_dict[col] = column_inconsistency(df[col])\n",
    "\n",
    "    return pd.DataFrame({'Column': list(inconsistency_dict.keys()), 'inconsistency': list(inconsistency_dict.values())})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd8e19e",
   "metadata": {},
   "source": [
    "#### Entropy M10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "043be51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_of_df(df):\n",
    "    \"\"\"\n",
    "    This function takes in a pandas dataframe and returns a dictionary with column names as keys and entropy as values.\n",
    "\n",
    "    Inputs:\n",
    "    A pandas dataframe with any number of columns and rows.\n",
    "\n",
    "    Outputs:\n",
    "    A dictionary with column names as keys and entropy as values.\n",
    "    \n",
    "    Important notes:\n",
    "    In the context of this function, a high entropy value for a column means that the values in that column are \n",
    "    diverse and spread out, with no single value being dominant or occurring significantly more frequently than \n",
    "    others. This can be an indication that the column contains important information and could potentially be a \n",
    "    good predictor in a machine learning model. On the other hand, a low entropy value for a column means that the \n",
    "    values in that column are more similar and possibly redundant, which may not provide much information gain in a \n",
    "    machine learning model.\n",
    "    \n",
    "    \"\"\"\n",
    "    entropies = []\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]) and not df[col].isnull().all():\n",
    "            # if column is numeric and not all NaN, use the probability density function to calculate the entropy\n",
    "            pdf, _ = np.histogram(df[col].dropna(), density=True)\n",
    "            entropies.append({'Column': col, 'Entropy': entropy(pdf, base=2)})\n",
    "        else:\n",
    "            # if column is not numeric or contains only NaN values, use value_counts to calculate the entropy\n",
    "            counts = df[col].value_counts(normalize=True)\n",
    "            entropies.append({'Column': col, 'Entropy': entropy(counts, base=2)})\n",
    "    return pd.DataFrame(entropies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe5061",
   "metadata": {},
   "source": [
    "#### Constancy M11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "244d3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_five_frequent_values(df):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe as input and returns a dictionary with each column's name as a key and the 5 most frequent values of that column as values. \n",
    "\n",
    "    Inputs:\n",
    "    A pandas dataframe with columns of any data type.\n",
    "\n",
    "    Outputs:\n",
    "    A dictionary with column names as keys and a list of 5 most frequent values as values.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Input:\n",
    "        col1  col2  col3\n",
    "    0     a     1     x\n",
    "    1     a     1     y\n",
    "    2     b     2     y\n",
    "    3     c     2     y\n",
    "    4     c     3     z\n",
    "    5     c     3     z\n",
    "\n",
    "\n",
    "    Output\n",
    "    {\n",
    "        'col1': ['c', 'a', 'b'],\n",
    "        'col2': [3, 2, 1],\n",
    "        'col3': ['y', 'z', 'x']\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    top_five_dict = {}\n",
    "    for col in df.columns:\n",
    "        top_five_dict[col] = list(df[col].value_counts().head(5).index)\n",
    "    return top_five_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9ce4df",
   "metadata": {},
   "source": [
    "#### Numer of Rows M12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad716bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_row_counts(df):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe as input and returns a dictionary with each column's name as a key and its row count as the value.\n",
    "\n",
    "    Inputs:\n",
    "    A pandas dataframe with columns of any data type.\n",
    "\n",
    "    Outputs:\n",
    "    A dictionary with column names as keys and number of rows as values.\n",
    "    \n",
    "    \n",
    "    Input\n",
    "       col1  col2  col3\n",
    "    0     a     1     x\n",
    "    1     a     NaN   y\n",
    "    2     b     2     y\n",
    "    3     NaN   2     y\n",
    "    4     c     3     z\n",
    "    5     c     3     NaN\n",
    "\n",
    "\n",
    "    Output\n",
    "    {\n",
    "        'col1': 4,\n",
    "        'col2': 5,\n",
    "        'col3': 4\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    column_row_counts = {}\n",
    "    for col in df.columns:\n",
    "        column_row_counts[col] = df[col].count()\n",
    "    return column_row_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3375acc9",
   "metadata": {},
   "source": [
    "#### Numer of Unique Values in Column M13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d160a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_unique_value_counts(df):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe as input and returns a dictionary with each column's name as a key and its unique value count as the value.\n",
    "\n",
    "    Inputs:\n",
    "    A pandas dataframe with columns of any data type.\n",
    "\n",
    "    Outputs:\n",
    "    A dictionary with column names as keys and number of unique values as values.\n",
    "    \n",
    "    \n",
    "    Input\n",
    "        col1  col2  col3\n",
    "    0     a     1     x\n",
    "    1     a     1     y\n",
    "    2     b     2     y\n",
    "    3     c     2     y\n",
    "    4     c     3     z\n",
    "    5     c     3     z\n",
    "\n",
    "\n",
    "    Output\n",
    "    {\n",
    "        'col1': 3,\n",
    "        'col2': 3,\n",
    "        'col3': 3\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    column_unique_counts = {}\n",
    "    for col in df.columns:\n",
    "        column_unique_counts[col] = df[col].nunique()\n",
    "    return column_unique_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e795493e",
   "metadata": {},
   "source": [
    "#### Numer of Duplicated Values in Column M14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "256bb6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_duplicate_counts(df):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe as input and returns a dictionary with each column's name as a key and its duplicate value count as the value.\n",
    "\n",
    "    Inputs:\n",
    "    A pandas dataframe with columns of any data type.\n",
    "\n",
    "    Outputs:\n",
    "    A dictionary with column names as keys and number of duplicates as values.\n",
    "    \n",
    "    \n",
    "    Input\n",
    "        col1  col2  col3\n",
    "    0     a     1     x\n",
    "    1     a     1     y\n",
    "    2     b     2     y\n",
    "    3     c     2     y\n",
    "    4     c     3     z\n",
    "    5     c     3     z\n",
    "\n",
    "    Output\n",
    "    {\n",
    "        'col1': 2,\n",
    "        'col2': 3,\n",
    "        'col3': 3\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    column_duplicate_counts = {}\n",
    "    for col in df.columns:\n",
    "        column_duplicate_counts[col] = sum(df[col].duplicated())\n",
    "    return column_duplicate_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa6e48b",
   "metadata": {},
   "source": [
    "#### Datatype Distribution M15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63761dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_datatype_percentage(df):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe as input and returns a dictionary with each column's name as a key and a nested dictionary as the value. In the nested dictionary, the keys are the data types present in that column and the values are the percentage of occurrences of each data type, including those with 0% occurrence.\n",
    "\n",
    "    Inputs:\n",
    "    A pandas dataframe with columns of any data type.\n",
    "\n",
    "    Outputs:\n",
    "    A dictionary with column names as keys and a nested dictionary as the value.\n",
    "    \n",
    "    \n",
    "    Input:\n",
    "         col1  col2  col3\n",
    "    0     a     1     True\n",
    "    1     b     2     False\n",
    "    2     c     NaN   True\n",
    "    3     d     4     True\n",
    "    4     e     NaN   False\n",
    "\n",
    "    Output:\n",
    "    {\n",
    "        'col1': {'str': 100.0, 'bool': 0.0, 'float': 0.0, 'unknown': 0.0},\n",
    "        'col2': {'int': 50.0, 'float': 50.0, 'bool': 0.0, 'unknown': 0.0},\n",
    "        'col3': {'bool': 60.0, 'unknown': 40.0, 'int': 0.0, 'float': 0.0}\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    column_datatype_percentage = {}\n",
    "    for col in df.columns:\n",
    "        datatype_counts = determine_data_type(df[[col]]).iloc[:, 0].value_counts()\n",
    "        datatype_percentage = datatype_counts / datatype_counts.sum() * 100\n",
    "        nested_dict = {k: v for k, v in zip(datatype_percentage.index, datatype_percentage)}\n",
    "        for datatype in set(determine_data_type(df[[col]]).iloc[:, 0].unique()) - set(datatype_percentage.index):\n",
    "            nested_dict[datatype] = 0\n",
    "        nested_dict_sorted = dict(sorted(nested_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "        column_datatype_percentage[col] = nested_dict_sorted\n",
    "    return column_datatype_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95af393",
   "metadata": {},
   "source": [
    "### Dataset Level Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0ab9c4",
   "metadata": {},
   "source": [
    "#### Numer of Rows in Dataset M16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18c1c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_count(df):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe as input and returns the number of rows in that dataframe.\n",
    "\n",
    "    Inputs:\n",
    "    A pandas dataframe with any number of rows.\n",
    "\n",
    "    Outputs:\n",
    "    An integer representing the number of rows in the input dataframe.\n",
    "    \n",
    "    \n",
    "    Input:\n",
    "        col1  col2  col3\n",
    "    0     1     a     True\n",
    "    1     2     b     False\n",
    "    2     3     c     True\n",
    "    3     4     d     False\n",
    "    4     5     e     True\n",
    "\n",
    "    Output:\n",
    "    5\n",
    "\n",
    "    \"\"\"\n",
    "    return df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15612cd6",
   "metadata": {},
   "source": [
    "#### Numer of Unique Rows in Dataset M17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46e449cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_row_count(df):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe as input and returns the number of unique rows in that dataframe.\n",
    "\n",
    "    Inputs:\n",
    "    A pandas dataframe with any number of rows.\n",
    "\n",
    "    Outputs:\n",
    "    An integer representing the number of unique rows in the input dataframe.\n",
    "    \n",
    "    input:\n",
    "        col1  col2  col3\n",
    "    0     1     a     True\n",
    "    1     2     b     False\n",
    "    2     3     c     True\n",
    "    3     4     d     False\n",
    "    4     5     e     True\n",
    "\n",
    "    output:\n",
    "    5\n",
    "\n",
    "    \"\"\"\n",
    "    return df.drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2364380b",
   "metadata": {},
   "source": [
    "#### Numer of Duplicates in Dataset M18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d97f9a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicate_row_count(df):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe as input and returns the number of duplicate rows in that dataframe.\n",
    "\n",
    "    Inputs:\n",
    "    A pandas dataframe with any number of rows.\n",
    "\n",
    "    Outputs:\n",
    "    An integer representing the number of duplicate rows in the input dataframe.\n",
    "    \n",
    "    Input:\n",
    "        col1  col2  col3\n",
    "    0     1     a     True\n",
    "    1     2     b     False\n",
    "    2     3     c     True\n",
    "    3     4     d     False\n",
    "    4     5     e     True\n",
    "    5     3     c     True\n",
    "    6     6     f     False\n",
    "\n",
    "    Output:\n",
    "    1\n",
    "\n",
    "    \"\"\"\n",
    "    return df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c93147d",
   "metadata": {},
   "source": [
    "### Conditions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c01ad9b",
   "metadata": {},
   "source": [
    "#### Missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33271cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def missing_c1(df):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe as input and returns a dataframe with two columns:\n",
    "    col1 = name of column in input df\n",
    "    col2 = percentage of missing values in that column\n",
    "\n",
    "    Inputs:\n",
    "    A pandas dataframe with any number of rows and columns.\n",
    "\n",
    "    Outputs:\n",
    "    A pandas dataframe containing the percentage of missing values in each column, sorted by percentage of missing values in descending order.\n",
    "    \"\"\"\n",
    "    # Compute the percentage of missing values in each column\n",
    "    missing_percents = df.isnull().mean() * 100\n",
    "\n",
    "    # Create a dataframe with the column names and their corresponding percentage of missing values\n",
    "    missing_df = pd.DataFrame({'Column Name': missing_percents.index, 'Missing %': missing_percents.values})\n",
    "\n",
    "    # Sort the dataframe by the percentage of missing values in descending order\n",
    "    missing_df = missing_df.sort_values(by='Missing %', ascending=False)\n",
    "\n",
    "    return missing_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aca924c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def col_duplicate_c2(df):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe as input and returns two outputs.\n",
    "    Output1 is a pandas dataframe with two columns representing the column names in the original dataframe and \n",
    "    the percentage of duplicates in that column, sorted in descending order.\n",
    "    Output2 is an integer representing the number of duplicate rows in the whole dataset.\n",
    "\n",
    "    Inputs:\n",
    "    A pandas dataframe with any number of rows and columns.\n",
    "\n",
    "    Outputs:\n",
    "    Output1 - A pandas dataframe with two columns and a single row for each column in the original dataframe that \n",
    "    has duplicate values. Column 1 represents the column names in the original dataframe. Column 2 represents \n",
    "    the percentage of duplicates in that column, sorted in descending order.\n",
    "    Output2 - An integer representing the number of duplicate rows in the whole dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the percentage of duplicates for each column in the dataframe\n",
    "    duplicate_percentage = []\n",
    "    for col in df.columns:\n",
    "        num_duplicates = df.duplicated(subset=[col]).sum()\n",
    "        col_percentage = (num_duplicates / df.shape[0]) * 100\n",
    "        if col_percentage > 0:\n",
    "            duplicate_percentage.append([col, col_percentage])\n",
    "    if len(duplicate_percentage) > 0:\n",
    "        # Create a pandas dataframe with the column names and their respective duplicate percentages\n",
    "        df_duplicate_percentage = pd.DataFrame(duplicate_percentage, columns=['Column Name', 'Duplicate Percentage'])\n",
    "        # Sort the dataframe in descending order based on the Duplicate Percentage column\n",
    "        df_duplicate_percentage = df_duplicate_percentage.sort_values('Duplicate Percentage', ascending=False)\n",
    "    else:\n",
    "        df_duplicate_percentage = pd.DataFrame(columns=['Column Name', 'Duplicate Percentage'])\n",
    "    # Get the number of rows in the whole dataset that are duplicates\n",
    "    num_rows_duplicates = df[df.duplicated()].shape[0]\n",
    "    # Return the pandas dataframe with the duplicate percentages and the number of rows in the whole dataset that are duplicates\n",
    "    return df_duplicate_percentage, num_rows_duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d8a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c84892d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "import pandas as pd\n",
    "\n",
    "def misspelled(df):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe as input and returns a tuple containing a list of column names with misspelled\n",
    "    words and a count of total misspelling occurrences.\n",
    "\n",
    "    Inputs:\n",
    "    A pandas dataframe with any number of rows and columns.\n",
    "\n",
    "    Outputs:\n",
    "    A tuple containing a list of strings representing the names of columns with misspelled words and an integer\n",
    "    representing the count of total misspelling occurrences.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a SpellChecker instance with the default language\n",
    "    spell = SpellChecker()\n",
    "\n",
    "    # Initialize an empty list to store column names with misspelled words\n",
    "    misspelled_cols = []\n",
    "\n",
    "    # Initialize a count of total misspellings\n",
    "    total_misspellings = 0\n",
    "\n",
    "    # Loop through each column in the input dataframe\n",
    "    for col in df.columns:\n",
    "        # Initialize a count of misspellings in the current column\n",
    "        col_misspellings = 0\n",
    "\n",
    "        # Loop through each cell in the current column\n",
    "        for val in df[col]:\n",
    "            # Check if the cell value is a string of length >= 2 and contains any misspelled words\n",
    "            if isinstance(val, str) and len(val) >= 2:\n",
    "                # Check if the cell value is not a number, time, or date\n",
    "                try:\n",
    "                    float_val = float(val)\n",
    "                    if float_val == int(float_val):\n",
    "                        val = int(float_val)\n",
    "                    else:\n",
    "                        continue\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                if \":\" in val or \"-\" in val or \"/\" in val:\n",
    "                    continue\n",
    "                # Check if the cell value contains multiple words\n",
    "                if \" \" in val:\n",
    "                    # Split the cell value into words and check each word for misspellings\n",
    "                    words = val.split()\n",
    "                    for word in words:\n",
    "                        if not spell.correction(word) == word:\n",
    "                            col_misspellings += 1\n",
    "                            total_misspellings += 1\n",
    "                # Check if the cell value is a single word and is misspelled\n",
    "                elif not spell.correction(val) == val:\n",
    "                    col_misspellings += 1\n",
    "                    total_misspellings += 1\n",
    "\n",
    "        # If the current column has at least one misspelled word, add its name to the list of misspelled columns\n",
    "        if col_misspellings > 0:\n",
    "            misspelled_cols.append(col)\n",
    "\n",
    "    # Return a tuple containing the list of misspelled columns and the total count of misspellings\n",
    "    return misspelled_cols, total_misspellings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d84e02c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_form_text(df):\n",
    "    # Determine data types of each cell in the input dataframe\n",
    "    data_types_df = determine_data_type(df)\n",
    "\n",
    "    # Get the length of each cell value in the input dataframe\n",
    "    value_lengths_df = value_length(df)\n",
    "\n",
    "    # Find cells with free-form text\n",
    "    free_form_mask = (data_types_df == 'str') & (value_lengths_df >= 50)\n",
    "\n",
    "    # Calculate percentage of rows with free-form text for each column\n",
    "    percentage_df = free_form_mask.apply(lambda x: round(sum(x) / len(x) * 100, 2))\n",
    "\n",
    "    # Combine column names and corresponding percentages in a new dataframe\n",
    "    output_df = pd.DataFrame({'Column Name': percentage_df.index, 'Percentage of Rows with Free-form Text': percentage_df.values})\n",
    "\n",
    "    # Sort the rows of the output dataframe in descending order\n",
    "    output_df = output_df.sort_values(by='Percentage of Rows with Free-form Text', ascending=False)\n",
    "\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafab17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3749c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datatype_mismatch(df):\n",
    "    # Determine data types of each cell in the input dataframe\n",
    "    data_types_df = determine_data_type(df)\n",
    "\n",
    "    # Determine the recommended datatype for each column\n",
    "    recommendation_df = pd.DataFrame(columns=['Column Name', 'Column Datatype', 'Recommended Datatype', 'Percentage of Recommended Cells'])\n",
    "\n",
    "    for col in data_types_df.columns:\n",
    "        # Determine the column datatype\n",
    "        col_dtype = df[col].dtype\n",
    "\n",
    "        # Calculate the percentage of cells with each datatype in the column\n",
    "        datatype_percentages = data_types_df[col].value_counts(normalize=True, dropna=False)\n",
    "\n",
    "        # Determine the most common datatype in the column\n",
    "        if (datatype_percentages.index[0] == 'unknown') and (len(datatype_percentages) < 2):\n",
    "            continue\n",
    "        elif (datatype_percentages.index[0] == 'unknown') and (len(datatype_percentages) > 1):\n",
    "            majority_datatype = datatype_percentages.index[1]\n",
    "        else:\n",
    "            majority_datatype = datatype_percentages.index[0]\n",
    "\n",
    "        # Determine the percentage of cells with the most common datatype\n",
    "        if majority_datatype not in str(col_dtype):\n",
    "            percentage = round(datatype_percentages[majority_datatype] * 100, 2)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Append the column name, column datatype, recommended datatype, and percentage to the recommendation dataframe\n",
    "        recommendation_df = pd.concat([recommendation_df, pd.DataFrame({'Column Name': [col], 'Column Datatype': [col_dtype],\n",
    "                                                                         'Recommended Datatype': [majority_datatype],\n",
    "                                                                         'Percentage of Recommended Cells': [percentage]})],\n",
    "                                      ignore_index=True)\n",
    "    \n",
    "    \n",
    "    recommendation_df['Column Name'] = recommendation_df['Column Name'].astype(str)\n",
    "    \n",
    "    # Sort the dataframe by 'Percentage of Recommended Cells' in descending order\n",
    "    recommendation_df = recommendation_df.sort_values(by=['Percentage of Recommended Cells'], ascending=False)\n",
    "\n",
    "    \n",
    "    return recommendation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a002acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_outliers(df):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe as input and returns a dataframe with column names and\n",
    "    the percentage of outliers in each column. If the column is numeric, z-score based outliers\n",
    "    are used. If the column is non-numeric, z-score based outliers based on cell value length are used.\n",
    "\n",
    "    Inputs:\n",
    "    A pandas dataframe with any number of columns and rows.\n",
    "\n",
    "    Outputs:\n",
    "    A dataframe with two columns: the first column contains column names, and the second column contains\n",
    "    the percentage of outliers in each column.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the helper functions\n",
    "    def column_outliers_numeric(num_z):\n",
    "        zscores = num_z\n",
    "        outliers = np.abs(zscores) > 3\n",
    "        return np.mean(outliers)\n",
    "\n",
    "    def column_outliers_nonnumeric(val_z):\n",
    "        zscores = val_z\n",
    "        outliers = np.abs(zscores) > 3\n",
    "        return np.mean(outliers)\n",
    "\n",
    "    # Determine column outliers for each column\n",
    "    outliers_dict = {}\n",
    "    num_z = z_score(df)\n",
    "    val_z = z_score_value_length(df)\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            if (col in num_z.columns):\n",
    "                outliers_dict[col] = column_outliers_numeric(num_z[col])\n",
    "        else:\n",
    "            if (col in val_z.columns):\n",
    "                outliers_dict[col] = column_outliers_nonnumeric(val_z[col])\n",
    "\n",
    "    # Convert dictionary to dataframe\n",
    "    outliers_df = pd.DataFrame(list(outliers_dict.items()), columns=['Column Name', 'Percentage of Outliers'])\n",
    "    \n",
    "    # Sort the dataframe by 'Percentage of Recommended Cells' in descending order\n",
    "    outliers_df = outliers_df.sort_values(by=['Percentage of Outliers'], ascending=False)\n",
    "\n",
    "\n",
    "    return outliers_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0008eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def misfielded(df):\n",
    "    def column_outliers_nonnumeric(val_z, df):\n",
    "        zscores = val_z\n",
    "        s_sorted = zscores.sort_values(ascending=False)\n",
    "        # get the fifth biggest value\n",
    "        p = s_sorted.iloc[6]\n",
    "        #percentile threshold \n",
    "        #p = zscores.quantile(0.999)\n",
    "        outliers = np.abs(zscores) > p\n",
    "        return df.where(outliers, other=np.nan) # return actual outlier values from the original DataFrame\n",
    "\n",
    "    val_z = z_score_value_length(df)\n",
    "    outliers_list = [column_outliers_nonnumeric(val_z[col], df)[col] for col in val_z.columns] # create list of outlier values for each column\n",
    "    outliers_df = pd.concat(outliers_list, axis=1) # concatenate outlier values into a single DataFrame\n",
    "    outliers_df.columns = val_z.columns # set column names to match those in val_z\n",
    "    outliers_df = outliers_df.dropna(how = 'all', axis=1)\n",
    "    return outliers_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931c3674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f1a9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def misfielded(df):\n",
    "    def column_outliers_nonnumeric(val_z, df):\n",
    "        zscores = val_z\n",
    "        s_sorted = zscores.sort_values(ascending=False)\n",
    "        # get the fifth biggest value\n",
    "        p = s_sorted.iloc[4]\n",
    "        #percentile threshold \n",
    "        #p = zscores.quantile(0.999)\n",
    "        outliers = np.abs(zscores) > p\n",
    "        return df.where(outliers, other=np.nan) # return actual outlier values from the original DataFrame\n",
    "\n",
    "    val_z = z_score_value_length(df)\n",
    "    outliers_list = [column_outliers_nonnumeric(val_z[col], df)[col] for col in val_z.columns] # create list of outlier values for each column\n",
    "    outliers_df = pd.concat(outliers_list, axis=1) # concatenate outlier values into a single DataFrame\n",
    "    outliers_df.columns = val_z.columns # set column names to match those in val_z\n",
    "    outliers_df = outliers_df.dropna(how = 'all', axis=1)\n",
    "\n",
    "\n",
    "    input_df = pd.DataFrame(outliers_df)\n",
    "\n",
    "    def get_compact_dataframe(df):\n",
    "        compact_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "        for col in df.columns:\n",
    "            tmp = df.copy()\n",
    "            non_null_values = (tmp[col].dropna().head(4)).tolist()  # Get up to first 5 non-null values\n",
    "            compact_df[col] = pd.Series(non_null_values)\n",
    "\n",
    "        return compact_df\n",
    "\n",
    "    result_df = get_compact_dataframe(input_df.copy())\n",
    "    return (result_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1790f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "162e34cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def incorrect(df):\n",
    "    \n",
    "    #t_inc = get_column_inconsistency(df)\n",
    "    #t_ent = entropy_of_df(df)\n",
    "    tmp = pd.merge(get_column_inconsistency(df), entropy_of_df(df), on='Column')\n",
    "    \n",
    "    i95 = tmp['inconsistency'].quantile(0.95)\n",
    "    i05 = tmp['inconsistency'].quantile(0.05)\n",
    "\n",
    "    e95 = tmp['Entropy'].quantile(0.95)\n",
    "    e05 = tmp['Entropy'].quantile(0.05)\n",
    "\n",
    "\n",
    "    print('\\n \\n Flag')\n",
    "    return (tmp[(tmp['inconsistency']>i95) | (tmp['inconsistency'] < i05) | (tmp['Entropy']>e95) | (tmp['Entropy']<e05)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1709ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11efe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78e99577",
   "metadata": {},
   "source": [
    "### Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33d78214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_r1(missing_df):\n",
    "    # Truncate long column names\n",
    "    missing_df['Column Name'] = missing_df['Column Name'].apply(lambda x: x[:65] + '...' if len(x) > 65 else x)\n",
    "    source = ColumnDataSource(missing_df[:12])\n",
    "    p = figure(y_range=source.data['Column Name'], x_axis_label='% Missing', y_axis_label='Column Name', title='Percentage of Missing Values by Column', width=800, height=600)\n",
    "    p.hbar(y='Column Name', right='Missing %', height=0.5, source=source)\n",
    "\n",
    "    # Save the plot to an HTML file\n",
    "    output_file('plot.html')\n",
    "    #save(p)\n",
    "\n",
    "    # Convert the dataframe to an HTML table\n",
    "    table_html = missing_df.to_html()\n",
    "\n",
    "    # Combine the plot and table HTML into a single HTML document\n",
    "    plot_html = file_html(p, CDN, \"plot\")\n",
    "    \n",
    "    html = f'<div style=\"display:flex; flex-direction:column; justify-content:center; align-items:center;\"><h2 style=\"text-align:center;\">Percentage of Missing Values</h2><div style=\"text-align:center;\">{plot_html}</div><br><div style=\"text-align:center;\">{table_html}</div></div>'\n",
    "\n",
    "    \n",
    "    return (html)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b856053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_r2(df_duplicate_percentage, num_rows_duplicates  ):\n",
    "    # Create a heading for the HTML element\n",
    "    heading_html = '<h2 style=\"text-align:center;\">Duplicates</h2>'\n",
    "\n",
    "    # Create a text for the HTML element\n",
    "    text_html = f'<p style=\"text-align:center;\">Provided dataset has {num_rows_duplicates} duplicate rows.</p>'\n",
    "\n",
    "    # Create a horizontal bar chart showing up to 12 columns with the highest percentage of duplicates\n",
    "    df_duplicate_percentage['Column Name'] = df_duplicate_percentage['Column Name'].apply(lambda x: x[:65] + '...' if len(x) > 65 else x)\n",
    "    source = ColumnDataSource(df_duplicate_percentage[:12])\n",
    "    p = figure(y_range=source.data['Column Name'], x_axis_label='% Duplicates', y_axis_label='Column Name', title='Percentage of Duplicates by Column', width=800, height=600)\n",
    "    p.hbar(y='Column Name', right='Duplicate Percentage', height=0.5, source=source)\n",
    "    plot_html = file_html(p, CDN, \"plot\")\n",
    "\n",
    "    # Convert the output dataframe from the col_duplicate_c2 function to HTML table\n",
    "    table_html = df_duplicate_percentage.to_html()\n",
    "\n",
    "    # Combine the heading, text, horizontal bar chart, and output dataframe into a single HTML document\n",
    "    html = f'<div style=\"display:flex; flex-direction:column; justify-content:center; align-items:center;\">{heading_html}{text_html}<div style=\"text-align:center;\">{plot_html}</div><br><div style=\"text-align:center;\">{table_html}</div></div>'\n",
    "\n",
    "    # Return the HTML element\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b385d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_form_text_html(output_df):\n",
    "    \"\"\"\n",
    "    This function takes the output dataframe of the free_form_text function as input and returns an HTML element\n",
    "    with a heading \"Free Form Text in Dataset\", a horizontal bar chart showing up to 12 columns with the highest\n",
    "    percentage of rows with free-form text, and a table displaying all columns with the corresponding percentages\n",
    "    of rows with free-form text.\n",
    "\n",
    "    Inputs:\n",
    "    The output dataframe of the free_form_text function.\n",
    "\n",
    "    Outputs:\n",
    "    An HTML element with a heading \"Free Form Text in Dataset\", a horizontal bar chart showing up to 12 columns with the\n",
    "    highest percentage of rows with free-form text, and a table displaying all columns with the corresponding percentages\n",
    "    of rows with free-form text.\n",
    "    \"\"\"\n",
    "\n",
    "    # Truncate column names longer than 65 characters\n",
    "    output_df['Column Name'] = output_df['Column Name'].apply(lambda x: x[:65] + '...' if len(x) > 65 else x)\n",
    "\n",
    "    # Create a heading for the HTML element\n",
    "    heading_html = '<h2 style=\"text-align:center;\">Free Form Text in Dataset</h2>'\n",
    "\n",
    "    # Create a horizontal bar chart showing up to 12 columns with the highest percentage of rows with free-form text\n",
    "    source = ColumnDataSource(output_df[:12])\n",
    "    p = figure(y_range=source.data['Column Name'], x_axis_label='% Rows with Free-form Text', y_axis_label='Column Name', title='Percentage of Rows with Free-form Text by Column', width=800, height=600)\n",
    "    p.hbar(y='Column Name', right='Percentage of Rows with Free-form Text', height=0.5, source=source)\n",
    "    plot_html = file_html(p, CDN, \"plot\")\n",
    "\n",
    "    # Convert the output dataframe to HTML table\n",
    "    table_html = output_df.to_html()\n",
    "\n",
    "    # Combine the heading, horizontal bar chart, and output dataframe into a single HTML document\n",
    "    html = f'<div style=\"display:flex; flex-direction:column; justify-content:center; align-items:center;\">{heading_html}<div style=\"text-align:center;\">{plot_html}</div><br><div style=\"text-align:center;\">{table_html}</div></div>'\n",
    "\n",
    "    # Return the HTML element\n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5801c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f299ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datatype_mismatch_html(output_df):\n",
    "    \"\"\"\n",
    "    This function takes the output dataframe of the datatype_mismatch function as input and returns an HTML element\n",
    "    with a heading \"Datatype Mismatch in Dataset\", a horizontal bar chart showing up to 12 columns with the highest\n",
    "    percentage of rows with datatype mismatch, and a table displaying all columns with the corresponding percentages\n",
    "    of rows with free-form text.\n",
    "\n",
    "    Inputs:\n",
    "    The output dataframe of the datatype mismatch function.\n",
    "\n",
    "    Outputs:\n",
    "    An HTML element with a heading \"Free Form Text in Dataset\", a horizontal bar chart showing up to 12 columns with the\n",
    "    highest percentage of rows with free-form text, and a table displaying all columns with the corresponding percentages\n",
    "    of rows with free-form text.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Truncate column names longer than 65 characters\n",
    "    output_df['Column Name'] = output_df['Column Name'].apply(lambda x: x[:65] + '...' if len(x) > 65 else x)\n",
    "    \n",
    "    tmp = output_df.copy()\n",
    "    \n",
    "    output_df = output_df[['Column Name','Percentage of Recommended Cells']]\n",
    "\n",
    "    # Create a heading for the HTML element\n",
    "    heading_html = '<h2 style=\"text-align:center;\">Datatype Mismatch in Dataset</h2>'\n",
    "\n",
    "    # Create a horizontal bar chart showing up to 12 columns with the highest percentage of rows with free-form text\n",
    "    sub = output_df[['Column Name', 'Percentage of Recommended Cells']]\n",
    "    source = ColumnDataSource(output_df[:12])\n",
    "    p = figure(y_range=source.data['Column Name'], x_axis_label='% Rows with Datatype Mismatch', y_axis_label='Column Name', title='Percentage of Rows with Datatype Mismatch by Column', width=800, height=600)\n",
    "    p.hbar(y='Column Name', right='Percentage of Recommended Cells', height=0.5, source=source)\n",
    "    plot_html = file_html(p, CDN, \"plot\")\n",
    "\n",
    "    # Convert the output dataframe to HTML table\n",
    "    #table_html = tmp.to_html(index=False)\n",
    "    table_html = tmp.to_html()\n",
    "\n",
    "    # Combine the heading, horizontal bar chart, and output dataframe into a single HTML document\n",
    "    html = f'<div style=\"display:flex; flex-direction:column; justify-content:center; align-items:center;\">{heading_html}<div style=\"text-align:center;\">{plot_html}</div><br><div style=\"text-align:center;\">{table_html}</div></div>'\n",
    "\n",
    "    # Return the HTML element\n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9bcdac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_outliers_html(output_df):\n",
    "    \"\"\"\n",
    "    This function takes the output dataframe of the datatype_mismatch function as input and returns an HTML element\n",
    "    with a heading \"Datatype Mismatch in Dataset\", a horizontal bar chart showing up to 12 columns with the highest\n",
    "    percentage of rows with datatype mismatch, and a table displaying all columns with the corresponding percentages\n",
    "    of rows with free-form text.\n",
    "\n",
    "    Inputs:\n",
    "    The output dataframe of the datatype mismatch function.\n",
    "\n",
    "    Outputs:\n",
    "    An HTML element with a heading \"Free Form Text in Dataset\", a horizontal bar chart showing up to 12 columns with the\n",
    "    highest percentage of rows with free-form text, and a table displaying all columns with the corresponding percentages\n",
    "    of rows with free-form text.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Truncate column names longer than 65 characters\n",
    "    output_df['Column Name'] = output_df['Column Name'].apply(lambda x: x[:65] + '...' if len(x) > 65 else x)\n",
    "\n",
    "    # Create a heading for the HTML element\n",
    "    heading_html = '<h2 style=\"text-align:center;\">Percentage of Rows With Outliers</h2>'\n",
    "\n",
    "    # Create a horizontal bar chart showing up to 12 columns with the highest percentage of rows with free-form text\n",
    "    source = ColumnDataSource(output_df[:12])\n",
    "    p = figure(y_range=source.data['Column Name'], x_axis_label='% Percentage of Outliers', y_axis_label='Column Name', title='Percentage of Rows with Outliers', width=800, height=600)\n",
    "    p.hbar(y='Column Name', right='Percentage of Outliers', height=0.5, source=source)\n",
    "    plot_html = file_html(p, CDN, \"plot\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Convert the output dataframe to HTML table\n",
    "    table_html = output_df.to_html()\n",
    "\n",
    "    # Combine the heading, horizontal bar chart, and output dataframe into a single HTML document\n",
    "    html = f'<div style=\"display:flex; flex-direction:column; justify-content:center; align-items:center;\">{heading_html}<div style=\"text-align:center;\">{plot_html}</div><br><div style=\"text-align:center;\">{table_html}</div></div>'\n",
    "\n",
    "    # Return the HTML element\n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7775ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def misfielded_html(tmp):\n",
    "    # Create a heading for the HTML element\n",
    "    heading_html = '<h2 style=\"text-align:center;\">Potentially Misfielded Values</h2>'\n",
    "    \n",
    "    n_cols = tmp.shape[1]\n",
    "\n",
    "    html_result = \"\"  # Create an empty string variable\n",
    "    \n",
    "    message = \"There are {n_cols} columns with potentially misfielded values:\\n\"\n",
    "\n",
    "\n",
    "    for col in tmp:\n",
    "        col_html = pd.DataFrame(tmp[col]).to_html()  # Get HTML for the current column\n",
    "        html_result += col_html + \"\\n\\n\"  # Append the HTML to the existing result with some space between them\n",
    "\n",
    "\n",
    "    # Concatenate the heading, message, and the HTML results\n",
    "    final_html = heading_html + message.format(n_cols=n_cols) + html_result\n",
    "    \n",
    "    # Wrap the final HTML with a <div> element and set text-align to center\n",
    "    final_html = f'<div style=\"text-align:center;\">{final_html}</div>'\n",
    "    \n",
    "    return final_html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b645337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a103ec27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea42593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0097d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3183291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dacf00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def structured_block(path, extension):\n",
    "    # Check if file extension is csv\n",
    "    if extension == '.csv':\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "    # Check if file extension is xls or xlsx\n",
    "    elif extension in ['.xls', '.xlsx']:\n",
    "        df = pd.read_excel(path)\n",
    "        \n",
    "    # Handle unrecognized file extension\n",
    "    else:\n",
    "        print(f\"Error: Unrecognized structured file extension: {extension}\")\n",
    "        df = None\n",
    "        return df\n",
    "    \n",
    "    # Generate HTML for missing values\n",
    "    missing_df = missing_c1(df)\n",
    "    html1 = missing_r1(missing_df)\n",
    "    \n",
    "    # Generate HTML for duplicates\n",
    "    dup_df , dup_row_cnt = col_duplicate_c2(df)\n",
    "    html2 = duplicate_r2(dup_df , dup_row_cnt)\n",
    "    \n",
    "    # Generate HTML for free-form text\n",
    "    fft = free_form_text(df)\n",
    "    html3 = free_form_text_html(fft)\n",
    "    \n",
    "    # Generate HTML for datatype mismatch\n",
    "    ddm = datatype_mismatch(df)\n",
    "    html4 = datatype_mismatch_html(ddm)\n",
    "    \n",
    "    # Generate HTML for column outliers\n",
    "    co = column_outliers(df)\n",
    "    html5 = column_outliers_html(co)\n",
    "    \n",
    "    # Generate HTML for potential misfielding\n",
    "    misf = misfielded(df)\n",
    "    html6 = misfielded_html(misf)\n",
    "    \n",
    "    # Generate recommendations\n",
    "    n_missing = len(missing_df)\n",
    "    rec1 = f\"<li>There are {n_missing} columns with missing values in the dataset. Review missing values table below to assess severity.</li>\"\n",
    "    \n",
    "    n_dup_col = len(dup_df)\n",
    "    rec2 = f\"<li>{dup_row_cnt} rows are duplicated over all columns. There are {n_dup_col} columns with duplicate values in the dataset. Review duplicates table below.</li>\"\n",
    "    \n",
    "    n_fft = len(fft[fft[\"Percentage of Rows with Free-form Text\"] > 0.0])\n",
    "    rec3 = f\"<li>There are {n_fft} columns with free form text. Review free-form-text table below for handling decisions.</li>\"\n",
    "    \n",
    "    n_ddm = len(ddm)\n",
    "    rec4 = f\"<li>There are {n_ddm} columns with datatype mismatch in the dataset. These columns have a datatype that is different from majority datatype of cell values. Review datatype mismatch table below.</li>\"\n",
    "    \n",
    "    n_co = len(co)\n",
    "    rec5 = f\"<li>There are {n_co} columns with outliers in the dataset. For numeric columns this refers to numeric value, for non-numeric columns this refers to value length. Refer to misfielded values table for handling decision.</li>\"\n",
    "    \n",
    "    n_misf = len(misf)\n",
    "    rec6 = f\"<li>There are {n_misf} columns with potential misfielding/incorrect values in the dataset. Refer to misfielding tables below to verify these entries.</li>\"\n",
    "    \n",
    "    # Combine HTML elements into a single document\n",
    "    merged_html = f\"\"\"\n",
    "        <html>\n",
    "            <head>\n",
    "            <h1>Data Profiling Report</h1>\n",
    "            </head>\n",
    "            <body>\n",
    "                <h2>Recommendations</h2>\n",
    "                <ul>\n",
    "                    {rec1}\n",
    "                    {rec2}\n",
    "                    {rec3}\n",
    "                    {rec4}\n",
    "                    {rec5}\n",
    "                    {rec6}\n",
    "                <h2>Anomolous Conditions Detected</h2\n",
    "                </ul>\n",
    "                {html1}\n",
    "                {html2}\n",
    "                {html3}\n",
    "                {html4}\n",
    "                {html5}\n",
    "                {html6}\n",
    "            </body>\n",
    "        </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('merged_output.html', 'w') as f:\n",
    "        f.write(merged_html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5b325ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "routes files to appropriate block depending on file type. \n",
    "\n",
    "eg. a structured csv is sent to the structured block. \n",
    "a semi structured json is sent to semi structured block, etc.\n",
    "\n",
    "'''\n",
    "def file_routing(filetype_dict, data_path):\n",
    "    if filetype_dict['classification'] == 'structured':\n",
    "        structured_block(data_path,filetype_dict['extension'])\n",
    "    #if filetype_dict['classification = semi-structured']:\n",
    "    #    semistructured_block(data_path,filetype_dict['extension'])\n",
    "    #if filetype_dict['classification = unstructured']:\n",
    "    #    unstructured_block(data_path,filetype_dict['extension'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "86d54b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main code block \n",
    "\n",
    "data_path = \"/Users/syedhadi/Desktop/datasets/mngr.csv\"\n",
    "info=check_input(data_path)\n",
    "file_routing(info, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a35f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f666ecfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1a6953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d9e27c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
